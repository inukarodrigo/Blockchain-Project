{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Using LSTM to train the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Sent tnx</th>\n",
       "      <th>Received Tnx</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total Ether sent</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>Total ERC20 tnxs</th>\n",
       "      <th>ERC20 uniq rec addr</th>\n",
       "      <th>ERC20 uniq rec contract addr</th>\n",
       "      <th>ERC20 min val rec</th>\n",
       "      <th>ERC20 uniq rec token name</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1093.71</td>\n",
       "      <td>704785.63</td>\n",
       "      <td>721</td>\n",
       "      <td>89</td>\n",
       "      <td>40</td>\n",
       "      <td>45.806785</td>\n",
       "      <td>6.589513</td>\n",
       "      <td>810</td>\n",
       "      <td>865.691093</td>\n",
       "      <td>586.466675</td>\n",
       "      <td>265.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2958.44</td>\n",
       "      <td>1218216.73</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2.613269</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>102</td>\n",
       "      <td>3.087297</td>\n",
       "      <td>3.085478</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2434.02</td>\n",
       "      <td>516729.30</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.165453</td>\n",
       "      <td>0.358906</td>\n",
       "      <td>12</td>\n",
       "      <td>3.588616</td>\n",
       "      <td>3.589057</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15785.09</td>\n",
       "      <td>397555.90</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>99.488840</td>\n",
       "      <td>34</td>\n",
       "      <td>1750.045862</td>\n",
       "      <td>895.399559</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10707.77</td>\n",
       "      <td>382472.42</td>\n",
       "      <td>4598</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>12.802411</td>\n",
       "      <td>2.671095</td>\n",
       "      <td>4619</td>\n",
       "      <td>104.318883</td>\n",
       "      <td>53.421897</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
       "0                       1093.71                                704785.63   \n",
       "1                       2958.44                               1218216.73   \n",
       "2                       2434.02                                516729.30   \n",
       "3                      15785.09                                397555.90   \n",
       "4                      10707.77                                382472.42   \n",
       "\n",
       "   Sent tnx  Received Tnx  Unique Received From Addresses  \\\n",
       "0       721            89                              40   \n",
       "1        94             8                               5   \n",
       "2         2            10                              10   \n",
       "3        25             9                               7   \n",
       "4      4598            20                               7   \n",
       "\n",
       "   max value received   avg val received  \\\n",
       "0            45.806785          6.589513   \n",
       "1             2.613269          0.385685   \n",
       "2             1.165453          0.358906   \n",
       "3           500.000000         99.488840   \n",
       "4            12.802411          2.671095   \n",
       "\n",
       "   total transactions (including tnx to create contract  total Ether sent  \\\n",
       "0                                                810           865.691093   \n",
       "1                                                102             3.087297   \n",
       "2                                                 12             3.588616   \n",
       "3                                                 34          1750.045862   \n",
       "4                                               4619           104.318883   \n",
       "\n",
       "   total ether received   Total ERC20 tnxs   ERC20 uniq rec addr  \\\n",
       "0            586.466675              265.0                  54.0   \n",
       "1              3.085478                8.0                   5.0   \n",
       "2              3.589057                8.0                   7.0   \n",
       "3            895.399559               14.0                  11.0   \n",
       "4             53.421897               42.0                  23.0   \n",
       "\n",
       "    ERC20 uniq rec contract addr   ERC20 min val rec  \\\n",
       "0                           58.0                 0.0   \n",
       "1                            7.0                 0.0   \n",
       "2                            8.0                 0.0   \n",
       "3                           11.0                 0.0   \n",
       "4                           27.0                 0.0   \n",
       "\n",
       "    ERC20 uniq rec token name  FLAG  \n",
       "0                        57.0     0  \n",
       "1                         7.0     0  \n",
       "2                         8.0     0  \n",
       "3                        11.0     0  \n",
       "4                        27.0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('modified_transaction_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the dataset is balanced or imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG\n",
       "0    7662\n",
       "1    2179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-fraudulent instances : 77.85794126613149\n",
      "Percentage of fraudulent instances : 22.14205873386851\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of non-fraudulent instances : {len(df.loc[df[\"FLAG\"]==0])/len(df[\"FLAG\"])*100}')\n",
    "print(f'Percentage of fraudulent instances : {len(df.loc[df[\"FLAG\"]==1])/len(df[\"FLAG\"])*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg min between received tnx                            0\n",
      "Time Diff between first and last (Mins)                 0\n",
      "Sent tnx                                                0\n",
      "Received Tnx                                            0\n",
      "Unique Received From Addresses                          0\n",
      "max value received                                      0\n",
      "avg val received                                        0\n",
      "total transactions (including tnx to create contract    0\n",
      "total Ether sent                                        0\n",
      "total ether received                                    0\n",
      " Total ERC20 tnxs                                       0\n",
      " ERC20 uniq rec addr                                    0\n",
      " ERC20 uniq rec contract addr                           0\n",
      " ERC20 min val rec                                      0\n",
      " ERC20 uniq rec token name                              0\n",
      "FLAG                                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9841, 15) (9841,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['FLAG'])\n",
    "y = df['FLAG']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7872, 15) (7872,)\n",
      "(1969, 15) (1969,)\n"
     ]
    }
   ],
   "source": [
    "# Split into training (80%) and testing set (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Sent tnx</th>\n",
       "      <th>Received Tnx</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total Ether sent</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>Total ERC20 tnxs</th>\n",
       "      <th>ERC20 uniq rec addr</th>\n",
       "      <th>ERC20 uniq rec contract addr</th>\n",
       "      <th>ERC20 min val rec</th>\n",
       "      <th>ERC20 uniq rec token name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310581</td>\n",
       "      <td>2.851119</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.133464</td>\n",
       "      <td>-0.066047</td>\n",
       "      <td>-0.031784</td>\n",
       "      <td>-0.130116</td>\n",
       "      <td>-0.095517</td>\n",
       "      <td>-0.026374</td>\n",
       "      <td>-0.031246</td>\n",
       "      <td>0.257603</td>\n",
       "      <td>0.198661</td>\n",
       "      <td>1.799837</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>1.868394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.339707</td>\n",
       "      <td>-0.675810</td>\n",
       "      <td>-0.153323</td>\n",
       "      <td>-0.176780</td>\n",
       "      <td>-0.106769</td>\n",
       "      <td>-0.043658</td>\n",
       "      <td>-0.183336</td>\n",
       "      <td>-0.211939</td>\n",
       "      <td>-0.028905</td>\n",
       "      <td>-0.033428</td>\n",
       "      <td>-0.075357</td>\n",
       "      <td>-0.075182</td>\n",
       "      <td>-0.214189</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.217464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.322958</td>\n",
       "      <td>1.063494</td>\n",
       "      <td>1.620329</td>\n",
       "      <td>1.238207</td>\n",
       "      <td>-0.096588</td>\n",
       "      <td>-0.041094</td>\n",
       "      <td>-0.182633</td>\n",
       "      <td>1.765804</td>\n",
       "      <td>-0.027951</td>\n",
       "      <td>-0.032487</td>\n",
       "      <td>-0.077685</td>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.273425</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.278813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503169</td>\n",
       "      <td>-0.553119</td>\n",
       "      <td>-0.153323</td>\n",
       "      <td>-0.174717</td>\n",
       "      <td>-0.099982</td>\n",
       "      <td>-0.043563</td>\n",
       "      <td>-0.182076</td>\n",
       "      <td>-0.209770</td>\n",
       "      <td>-0.028905</td>\n",
       "      <td>-0.033426</td>\n",
       "      <td>-0.077685</td>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.273425</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.278813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.339693</td>\n",
       "      <td>-0.674831</td>\n",
       "      <td>-0.150720</td>\n",
       "      <td>-0.174717</td>\n",
       "      <td>-0.099982</td>\n",
       "      <td>-0.038450</td>\n",
       "      <td>-0.055912</td>\n",
       "      <td>-0.209047</td>\n",
       "      <td>-0.028650</td>\n",
       "      <td>-0.033180</td>\n",
       "      <td>-0.077685</td>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.273425</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.278813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>-0.320304</td>\n",
       "      <td>-0.672906</td>\n",
       "      <td>-0.152022</td>\n",
       "      <td>-0.174717</td>\n",
       "      <td>-0.099982</td>\n",
       "      <td>-0.043444</td>\n",
       "      <td>-0.179100</td>\n",
       "      <td>-0.209770</td>\n",
       "      <td>-0.028896</td>\n",
       "      <td>-0.033420</td>\n",
       "      <td>-0.075357</td>\n",
       "      <td>-0.075182</td>\n",
       "      <td>-0.214189</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.217464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>-0.250448</td>\n",
       "      <td>0.336370</td>\n",
       "      <td>-0.140310</td>\n",
       "      <td>-0.024143</td>\n",
       "      <td>0.358138</td>\n",
       "      <td>-0.042296</td>\n",
       "      <td>-0.179728</td>\n",
       "      <td>-0.097686</td>\n",
       "      <td>-0.028370</td>\n",
       "      <td>-0.032907</td>\n",
       "      <td>-0.066043</td>\n",
       "      <td>-0.039464</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>0.027931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>-0.339707</td>\n",
       "      <td>-0.675610</td>\n",
       "      <td>-0.152022</td>\n",
       "      <td>-0.175749</td>\n",
       "      <td>-0.103375</td>\n",
       "      <td>-0.043642</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>-0.210493</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>-0.033428</td>\n",
       "      <td>-0.077685</td>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.273425</td>\n",
       "      <td>-0.025533</td>\n",
       "      <td>-0.278813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>0.012046</td>\n",
       "      <td>-0.061022</td>\n",
       "      <td>-0.140310</td>\n",
       "      <td>-0.161310</td>\n",
       "      <td>-0.062654</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.187543</td>\n",
       "      <td>-0.193861</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.027996</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>-0.039464</td>\n",
       "      <td>-0.036481</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>-0.033418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>-0.271446</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>-0.153323</td>\n",
       "      <td>-0.031362</td>\n",
       "      <td>-0.093195</td>\n",
       "      <td>-0.043584</td>\n",
       "      <td>-0.182561</td>\n",
       "      <td>-0.109256</td>\n",
       "      <td>-0.028905</td>\n",
       "      <td>-0.033322</td>\n",
       "      <td>-0.070700</td>\n",
       "      <td>-0.051370</td>\n",
       "      <td>-0.095717</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>-0.094766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7872 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
       "0                         0.310581                                 2.851119   \n",
       "1                        -0.339707                                -0.675810   \n",
       "2                        -0.322958                                 1.063494   \n",
       "3                         0.503169                                -0.553119   \n",
       "4                        -0.339693                                -0.674831   \n",
       "...                            ...                                      ...   \n",
       "7867                     -0.320304                                -0.672906   \n",
       "7868                     -0.250448                                 0.336370   \n",
       "7869                     -0.339707                                -0.675610   \n",
       "7870                      0.012046                                -0.061022   \n",
       "7871                     -0.271446                                 0.024700   \n",
       "\n",
       "      Sent tnx  Received Tnx  Unique Received From Addresses  \\\n",
       "0     0.001530     -0.133464                       -0.066047   \n",
       "1    -0.153323     -0.176780                       -0.106769   \n",
       "2     1.620329      1.238207                       -0.096588   \n",
       "3    -0.153323     -0.174717                       -0.099982   \n",
       "4    -0.150720     -0.174717                       -0.099982   \n",
       "...        ...           ...                             ...   \n",
       "7867 -0.152022     -0.174717                       -0.099982   \n",
       "7868 -0.140310     -0.024143                        0.358138   \n",
       "7869 -0.152022     -0.175749                       -0.103375   \n",
       "7870 -0.140310     -0.161310                       -0.062654   \n",
       "7871 -0.153323     -0.031362                       -0.093195   \n",
       "\n",
       "      max value received   avg val received  \\\n",
       "0               -0.031784         -0.130116   \n",
       "1               -0.043658         -0.183336   \n",
       "2               -0.041094         -0.182633   \n",
       "3               -0.043563         -0.182076   \n",
       "4               -0.038450         -0.055912   \n",
       "...                   ...               ...   \n",
       "7867            -0.043444         -0.179100   \n",
       "7868            -0.042296         -0.179728   \n",
       "7869            -0.043642         -0.182894   \n",
       "7870             0.158200          0.187543   \n",
       "7871            -0.043584         -0.182561   \n",
       "\n",
       "      total transactions (including tnx to create contract  total Ether sent  \\\n",
       "0                                             -0.095517            -0.026374   \n",
       "1                                             -0.211939            -0.028905   \n",
       "2                                              1.765804            -0.027951   \n",
       "3                                             -0.209770            -0.028905   \n",
       "4                                             -0.209047            -0.028650   \n",
       "...                                                 ...                  ...   \n",
       "7867                                          -0.209770            -0.028896   \n",
       "7868                                          -0.097686            -0.028370   \n",
       "7869                                          -0.210493            -0.028904   \n",
       "7870                                          -0.193861            -0.023335   \n",
       "7871                                          -0.109256            -0.028905   \n",
       "\n",
       "      total ether received   Total ERC20 tnxs   ERC20 uniq rec addr  \\\n",
       "0                -0.031246           0.257603              0.198661   \n",
       "1                -0.033428          -0.075357             -0.075182   \n",
       "2                -0.032487          -0.077685             -0.087088   \n",
       "3                -0.033426          -0.077685             -0.087088   \n",
       "4                -0.033180          -0.077685             -0.087088   \n",
       "...                    ...                ...                   ...   \n",
       "7867             -0.033420          -0.075357             -0.075182   \n",
       "7868             -0.032907          -0.066043             -0.039464   \n",
       "7869             -0.033428          -0.077685             -0.087088   \n",
       "7870             -0.027996          -0.068372             -0.039464   \n",
       "7871             -0.033322          -0.070700             -0.051370   \n",
       "\n",
       "       ERC20 uniq rec contract addr   ERC20 min val rec  \\\n",
       "0                          1.799837           -0.025533   \n",
       "1                         -0.214189           -0.025533   \n",
       "2                         -0.273425           -0.025533   \n",
       "3                         -0.273425           -0.025533   \n",
       "4                         -0.273425           -0.025533   \n",
       "...                             ...                 ...   \n",
       "7867                      -0.214189           -0.025533   \n",
       "7868                       0.022755           -0.025533   \n",
       "7869                      -0.273425           -0.025533   \n",
       "7870                      -0.036481           -0.025451   \n",
       "7871                      -0.095717           -0.025489   \n",
       "\n",
       "       ERC20 uniq rec token name  \n",
       "0                       1.868394  \n",
       "1                      -0.217464  \n",
       "2                      -0.278813  \n",
       "3                      -0.278813  \n",
       "4                      -0.278813  \n",
       "...                          ...  \n",
       "7867                   -0.217464  \n",
       "7868                    0.027931  \n",
       "7869                   -0.278813  \n",
       "7870                   -0.033418  \n",
       "7871                   -0.094766  \n",
       "\n",
       "[7872 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the values of X_train after scaling\n",
    "sc_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "sc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training before SMOTE: ((7872, 15), (7872,))\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "print(f'Shape of the training before SMOTE: {X_train_scaled.shape, y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training after SMOTE: ((12230, 15), (12230,))\n"
     ]
    }
   ],
   "source": [
    "X_train_resampled, y_train_resampled = oversample.fit_resample(X_train_scaled, y_train)\n",
    "print(f'Shape of the training after SMOTE: {X_train_resampled.shape, y_train_resampled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE OVERSAMPLING \n",
      " \tNon-frauds: 6115 \n",
      " \tFauds: 1757\n",
      "AFTER OVERSAMPLING \n",
      " \tNon-frauds: 6115 \n",
      " \tFauds: 6116\n"
     ]
    }
   ],
   "source": [
    "# Target distribution before SMOTE\n",
    "non_fraud = 0\n",
    "fraud = 0\n",
    "\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        non_fraud +=1\n",
    "    else:\n",
    "        fraud +=1\n",
    "\n",
    "# Target distribution after SMOTE\n",
    "no = 0\n",
    "yes = 1\n",
    "\n",
    "for j in y_train_resampled:\n",
    "    if j == 0:\n",
    "        no +=1\n",
    "    else:\n",
    "        yes +=1\n",
    "\n",
    "\n",
    "print(f'BEFORE OVERSAMPLING \\n \\tNon-frauds: {non_fraud} \\n \\tFauds: {fraud}')\n",
    "print(f'AFTER OVERSAMPLING \\n \\tNon-frauds: {no} \\n \\tFauds: {yes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the input data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test_lstm = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12230, 15, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lstm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing modules for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 64, return_sequences=True, input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 64, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 64, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 64))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "383/383 [==============================] - 64s 83ms/step - loss: 0.5946\n",
      "Epoch 2/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.5306\n",
      "Epoch 3/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.4216\n",
      "Epoch 4/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.2660\n",
      "Epoch 5/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.2394\n",
      "Epoch 6/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.2321\n",
      "Epoch 7/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.2141\n",
      "Epoch 8/100\n",
      "383/383 [==============================] - 33s 85ms/step - loss: 0.2030\n",
      "Epoch 9/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1854\n",
      "Epoch 10/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1761\n",
      "Epoch 11/100\n",
      "383/383 [==============================] - 34s 88ms/step - loss: 0.1666\n",
      "Epoch 12/100\n",
      "383/383 [==============================] - 30s 79ms/step - loss: 0.1674\n",
      "Epoch 13/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1584\n",
      "Epoch 14/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.1570\n",
      "Epoch 15/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1563\n",
      "Epoch 16/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1471\n",
      "Epoch 17/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.1467\n",
      "Epoch 18/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1465\n",
      "Epoch 19/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1404\n",
      "Epoch 20/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1360\n",
      "Epoch 21/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1374\n",
      "Epoch 22/100\n",
      "383/383 [==============================] - 32s 85ms/step - loss: 0.1356\n",
      "Epoch 23/100\n",
      "383/383 [==============================] - 34s 88ms/step - loss: 0.1284\n",
      "Epoch 24/100\n",
      "383/383 [==============================] - 34s 88ms/step - loss: 0.1373\n",
      "Epoch 25/100\n",
      "383/383 [==============================] - 34s 88ms/step - loss: 0.1297\n",
      "Epoch 26/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1297\n",
      "Epoch 27/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1277\n",
      "Epoch 28/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1261\n",
      "Epoch 29/100\n",
      "383/383 [==============================] - 32s 85ms/step - loss: 0.1283\n",
      "Epoch 30/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.1197\n",
      "Epoch 31/100\n",
      "383/383 [==============================] - 31s 82ms/step - loss: 0.1192\n",
      "Epoch 32/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1223\n",
      "Epoch 33/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1204\n",
      "Epoch 34/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1166\n",
      "Epoch 35/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1160\n",
      "Epoch 36/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1133\n",
      "Epoch 37/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1132\n",
      "Epoch 38/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.1099\n",
      "Epoch 39/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1098\n",
      "Epoch 40/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.1132\n",
      "Epoch 41/100\n",
      "383/383 [==============================] - 32s 85ms/step - loss: 0.1133\n",
      "Epoch 42/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1064\n",
      "Epoch 43/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1044\n",
      "Epoch 44/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1094\n",
      "Epoch 45/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.1075\n",
      "Epoch 46/100\n",
      "383/383 [==============================] - 31s 82ms/step - loss: 0.1028\n",
      "Epoch 47/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1020\n",
      "Epoch 48/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1028\n",
      "Epoch 49/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.0999\n",
      "Epoch 50/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1026\n",
      "Epoch 51/100\n",
      "383/383 [==============================] - 33s 86ms/step - loss: 0.1003\n",
      "Epoch 52/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.1008\n",
      "Epoch 53/100\n",
      "383/383 [==============================] - 33s 87ms/step - loss: 0.0995\n",
      "Epoch 54/100\n",
      "383/383 [==============================] - 31s 81ms/step - loss: 0.0996\n",
      "Epoch 55/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.0983\n",
      "Epoch 56/100\n",
      "383/383 [==============================] - 32s 82ms/step - loss: 0.0993\n",
      "Epoch 57/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0955\n",
      "Epoch 58/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.0960\n",
      "Epoch 59/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0972\n",
      "Epoch 60/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0995\n",
      "Epoch 61/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0926\n",
      "Epoch 62/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0971\n",
      "Epoch 63/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0931\n",
      "Epoch 64/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0907\n",
      "Epoch 65/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0887\n",
      "Epoch 66/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0922\n",
      "Epoch 67/100\n",
      "383/383 [==============================] - 31s 81ms/step - loss: 0.0948\n",
      "Epoch 68/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0934\n",
      "Epoch 69/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0878\n",
      "Epoch 70/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0935\n",
      "Epoch 71/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0873\n",
      "Epoch 72/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0869\n",
      "Epoch 73/100\n",
      "383/383 [==============================] - 31s 81ms/step - loss: 0.0874\n",
      "Epoch 74/100\n",
      "383/383 [==============================] - 30s 78ms/step - loss: 0.0870\n",
      "Epoch 75/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.0850\n",
      "Epoch 76/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0831\n",
      "Epoch 77/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0856\n",
      "Epoch 78/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0849\n",
      "Epoch 79/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0875\n",
      "Epoch 80/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0831\n",
      "Epoch 81/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0810\n",
      "Epoch 82/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0864\n",
      "Epoch 83/100\n",
      "383/383 [==============================] - 31s 81ms/step - loss: 0.0845\n",
      "Epoch 84/100\n",
      "383/383 [==============================] - 31s 82ms/step - loss: 0.0847\n",
      "Epoch 85/100\n",
      "383/383 [==============================] - 30s 78ms/step - loss: 0.0893\n",
      "Epoch 86/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0801\n",
      "Epoch 87/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0820\n",
      "Epoch 88/100\n",
      "383/383 [==============================] - 32s 82ms/step - loss: 0.0842\n",
      "Epoch 89/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0793\n",
      "Epoch 90/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0800\n",
      "Epoch 91/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.0835\n",
      "Epoch 92/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0788\n",
      "Epoch 93/100\n",
      "383/383 [==============================] - 32s 84ms/step - loss: 0.0829\n",
      "Epoch 94/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0804\n",
      "Epoch 95/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0771\n",
      "Epoch 96/100\n",
      "383/383 [==============================] - 31s 81ms/step - loss: 0.0774\n",
      "Epoch 97/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0792\n",
      "Epoch 98/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0743\n",
      "Epoch 99/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0748\n",
      "Epoch 100/100\n",
      "383/383 [==============================] - 32s 83ms/step - loss: 0.0765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2459251ac90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the training set\n",
    "regressor.fit(X_train_lstm, y_train_resampled, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 3s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_probs = regressor.predict(X_test_lstm)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary (0 or 1)\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1547\n",
      "           1       0.85      0.94      0.89       422\n",
      "\n",
      "    accuracy                           0.95      1969\n",
      "   macro avg       0.91      0.95      0.93      1969\n",
      "weighted avg       0.95      0.95      0.95      1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the scaler to a file\n",
    "import joblib\n",
    "joblib.dump(sc, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to a file\n",
    "regressor.save('trained_LSTM_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to build the LSTM model\n",
    "def create_model(optimizer='adam', dropout_rate=0.0, units=64, num_layers=1):\n",
    "    model = Sequential()\n",
    "    for _ in range(num_layers):\n",
    "        model.add(LSTM(units, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating KerasClassifier for use with GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'model__optimizer': ['adam', 'rmsprop'],\n",
    "    'model__dropout_rate': [0.2, 0.3],\n",
    "    'model__units': [32, 64, 128],\n",
    "    'model__num_layers': [1, 2, 3, 4, 5],\n",
    "    'epochs': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "    'batch_size': [32, 64, 128]     # Batch size during training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train_lstm, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and the corresponding accuracy\n",
    "best_params = grid_result.best_params_\n",
    "best_accuracy = grid_result.best_score_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred_probs = best_model.predict(X_test_lstm)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler to a file\n",
    "import joblib\n",
    "joblib.dump(sc, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model using joblib\n",
    "joblib.dump(best_model, 'best_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
